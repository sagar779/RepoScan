# Migration & Refactoring Strategy Guide

This document provides a strategic approach to handling the findings generated by RepoScan, specifically focusing on AJAX and Dynamic Content.

---

## 1. Migration Priority: AJAX Calls

Your **Analysis.xlsx** report provides an inventory of "Real" AJAX calls. Use this as your migration checklist.

### Strategy
1.  **Inventory**: Filter the Excel report for `Is_Counted = Yes`.
2.  **Endpoint Mapping**: Create a map of `Legacy URL` -> `New API Endpoint`.
    *   *Static URLs*: Easy 1-to-1 map.
    *   *Dynamic URLs* (marked `Dynamic/Variable`): Open the file and trace the variable to finding the endpoint logic.
3.  **Implementation**:
    *   Move the logic to a service layer (e.g., `UserService.ts`).
    *   Replace `$.ajax` settings with a global configuration (e.g., Axios instance).

---

## 2. Refactoring Dynamic Writes

When RepoScan flags "Dynamic JS/HTML Generation", it means the legacy code is building UI strings manually. This is the **hardest** part of migration.

### Difficulty Levels

#### Level 1: Data Binding (Easy)
*   **The Pattern**: `div.innerHTML = "Hello " + userName`
*   **The Fix**: Use your framework's binding syntax.
    *   *React*: `<div>Hello {userName}</div>`
    *   *Vue*: `<div>Hello {{ userName }}</div>`
*   **Time**: Minutes per instance.

#### Level 2: HTML Fragments (Medium)
*   **The Pattern**: `div.innerHTML = "<div class='card'>" + title + "</div>"`
*   **The Fix**: Extract this into a reusable **Component**.
    *   *Action*: Create `CardComponent`. Pass `title` as a prop.
*   **Time**: Hours (requires creating new files).

#### Level 3: Script Injection (Hard)
*   **The Pattern**: `div.innerHTML = "<script>doSomething()</script>"` or `eval(code)`
*   **The Problem**: Modern frameworks block this for security.
*   **The Fix**: **Logic Extraction**.
    *   Find what `doSomething()` does.
    *   Move it to a lifecycle hook (e.g., `useEffect`, `onMounted`).
    *   **Do not** try to inject the script tag. Run the functions directly.
*   **Time**: Days (requires reverse-engineering logic).

---

## 3. The "Refactoring Assessment" Tool
Use the generated `Refactoring_Assessment.xlsx` to prioritize work.

*   **Status: Ready**: Safe to copy logic structure (mostly pure JS).
*   **Status: Needs Rewrite**: Contains Event Handlers (`onclick`) or `document.write`. Requires syntax changes.
*   **Status: Blocked**: Contains Server-Side code (`<% %>`, `@Model`). **Do not move**. These require backend API development first.

### Workflow
1.  **Blocker Pass**: Address all "Blocked" items by building necessary Backend APIs.
2.  **Rewrite Pass**: Tackle "Needs Rewrite" items, converting dynamic sinks to Components.
3.  **Migration Pass**: Move "Ready" items and wire them up.

---

## 4. Optimized Crawling Strategy (The "Hybrid" Workflow)

To reduce time and avoid "blindly" crawling thousands of pages, use **Static-Fed Crawling**.

### Why this is better
*   **Blind Crawling**: Slow, redundant (visits same links repeatedly), misses orphan pages.
*   **Targeted Crawling**: Fast, 100% coverage of known assets.

### The Workflow
1.  **Inventory**: Run the Static Scanner (RepoScan) to get a list of all `.aspx`, `.html`, `.php` files.
2.  **Transform**: Convert these file paths to Source URLs manually or via script.
    *   Example: `C:\MyProject\Views\Admin\Users.aspx` -> `http://localhost/Admin/Users.aspx`
3.  **Target**: Feed this specific list of URLs to the crawler with `Depth = 0`.
    *   The crawler will visit each page *once*, verify dependencies (CSP/Scripts), and stop.

This approach ensures you validate every page you own without wasting time spidering the web.
